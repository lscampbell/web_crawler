# web_crawler
Simple web crawler for finding endpoints.

Features:
1) All crawled URLs are organized by page extensions.
2) All parameters of same URL are organized and displayed together.


#Running from terminal

![Alt text](https://github.com/lscampbell/web_crawler/raw/master/1111.png "")

#Accessing crawled links 

![Alt text](https://github.com/lscampbell/web_crawler/raw/master/2.png "")

![Alt text](https://github.com/lscampbell/web_crawler/raw/master/3.png "")

#Installation

pip3 install nyawc

git clone https://github.com/lscampbell/web_crawler.git

cd web-crawler

python3 web_crawler.py

webpage at http://localhost:8089 
